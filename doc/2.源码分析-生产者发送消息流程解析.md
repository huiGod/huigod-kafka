[TOC]

客户端发送消息核心流程：

1. 阻塞式获取MetaData,超过${max.block.ms}时间依旧未获取到,则抛TimeoutException,消息发送失败
2. 对消息的key与value进行序列化
3. 根据消息计算其将要发往的分区,若客户端发送消息时指定partitionId,则直接返回所指定的partitionId,否则根据分区器定义的分区分配策略计算出 partitionId
4. 消息长度有效性检查,超过${max.request.size}或${buffer.memory}所设阈值,都会抛RecordTooLargeException
5. 创建TopicPartition对象(记录消息的topic与分区信息),在RecordAccumulator中会为每个TopicPartiton对象创建一个双端队列
6. 构造Callback对象,该对象最终会交由ProducerBatch处理
7. 写BufferPool操作,这一步是调用RecordAccumulator.append()方法将ProducerRecord写入RecordAccumulator 的BufferPool中,并返回处理结果

# 客户端KafkaProducer初始化

KafkaProducer是Kafka生产者客户端，用于发送消息到Kafka集群。并且，KafkaProducer是线程安全，能够通过多线程并发安全的发送消息，简单的使用方式如下：

```java
Properties props = new Properties();
props.put("bootstrap.servers", "localhost:9092");
props.put("acks", "all");
props.put("retries", 0);
props.put("batch.size", 16384);
props.put("linger.ms", 1);
props.put("buffer.memory", 33554432);
props.put("key.serializer", "org.apache.kafka.common.serialization.StringSerializer");
props.put("value.serializer", "org.apache.kafka.common.serialization.StringSerializer");

Producer<String, String> producer = new KafkaProducer<>(props);
for(int i = 0; i < 100; i++)
  producer.send(new ProducerRecord<String, String>("my-topic", Integer.toString(i), Integer.toString(i)));

producer.close();
```

构造器初始化源码如下：

```java
private KafkaProducer(ProducerConfig config, Serializer<K> keySerializer, Serializer<V> valueSerializer) {
    try {
        log.trace("Starting the Kafka producer");
        //解析传入的多个配置项
        Map<String, Object> userProvidedConfigs = config.originals();
        this.producerConfig = config;
        this.time = new SystemTime();

        clientId = config.getString(ProducerConfig.CLIENT_ID_CONFIG);
        if (clientId.length() <= 0)
          //clientId默认是前缀加自增 id
          clientId = "producer-" + PRODUCER_CLIENT_ID_SEQUENCE.getAndIncrement();
        Map<String, String> metricTags = new LinkedHashMap<String, String>();
        metricTags.put("client-id", clientId);
      //监控相关指标
      MetricConfig metricConfig = new MetricConfig().samples(config.getInt(ProducerConfig.METRICS_NUM_SAMPLES_CONFIG))
                .timeWindow(config.getLong(ProducerConfig.METRICS_SAMPLE_WINDOW_MS_CONFIG), TimeUnit.MILLISECONDS)
                .tags(metricTags);
        List<MetricsReporter> reporters = config.getConfiguredInstances(ProducerConfig.METRIC_REPORTER_CLASSES_CONFIG,
                MetricsReporter.class);
        reporters.add(new JmxReporter(JMX_PREFIX));
        this.metrics = new Metrics(metricConfig, reporters, time);
        //核心组件:分区器，后续用来决定发送的每条消息路由到 Topic 对应的哪个分区
        this.partitioner = config.getConfiguredInstance(ProducerConfig.PARTITIONER_CLASS_CONFIG, Partitioner.class);
        //配置retry.banckoff.ms重试时间间隔，默认100ms
        long retryBackoffMs = config.getLong(ProducerConfig.RETRY_BACKOFF_MS_CONFIG);
        //核心组件：管理元数据组件，负责从 broker 集群拉取元数据的 Topics(Topic->Prititions(Leader+Followers,ISR))
        //默认每隔 metadata.max.age.ms强制刷新，默认5分钟
        //如果写入的 Topic 对应元数据不在本地，也会发送请求到 broker 尝试获取对应元数据
        //broker 集群增加了 broker，也会涉及到元数据变化
        this.metadata = new Metadata(retryBackoffMs, config.getLong(ProducerConfig.METADATA_MAX_AGE_CONFIG));
        //发送请求 request（包含多个 batch）的最大字节数max.request.size，默认1M
        this.maxRequestSize = config.getInt(ProducerConfig.MAX_REQUEST_SIZE_CONFIG);
        //缓冲区大小 buffer.memory，默认32M
        //如果生产者速度太快，导致缓冲区满，会阻塞生产者最长60s，最终抛出异常
        this.totalMemorySize = config.getLong(ProducerConfig.BUFFER_MEMORY_CONFIG);
        //压缩方式，默认不压缩
        this.compressionType = CompressionType.forName(config.getString(ProducerConfig.COMPRESSION_TYPE_CONFIG));
        /* check for user defined settings.
         * If the BLOCK_ON_BUFFER_FULL is set to true,we do not honor METADATA_FETCH_TIMEOUT_CONFIG.
         * This should be removed with release 0.9 when the deprecated configs are removed.
         */
        //请求最长被阻塞时间max.block.ms，默认60s
        if (userProvidedConfigs.containsKey(ProducerConfig.BLOCK_ON_BUFFER_FULL_CONFIG)) {
            log.warn(ProducerConfig.BLOCK_ON_BUFFER_FULL_CONFIG + " config is deprecated and will be removed soon. " +
                    "Please use " + ProducerConfig.MAX_BLOCK_MS_CONFIG);
            boolean blockOnBufferFull = config.getBoolean(ProducerConfig.BLOCK_ON_BUFFER_FULL_CONFIG);
            if (blockOnBufferFull) {
                this.maxBlockTimeMs = Long.MAX_VALUE;
            } else if (userProvidedConfigs.containsKey(ProducerConfig.METADATA_FETCH_TIMEOUT_CONFIG)) {
                log.warn(ProducerConfig.METADATA_FETCH_TIMEOUT_CONFIG + " config is deprecated and will be removed soon. " +
                        "Please use " + ProducerConfig.MAX_BLOCK_MS_CONFIG);
                this.maxBlockTimeMs = config.getLong(ProducerConfig.METADATA_FETCH_TIMEOUT_CONFIG);
            } else {
                this.maxBlockTimeMs = config.getLong(ProducerConfig.MAX_BLOCK_MS_CONFIG);
            }
        } else if (userProvidedConfigs.containsKey(ProducerConfig.METADATA_FETCH_TIMEOUT_CONFIG)) {
            log.warn(ProducerConfig.METADATA_FETCH_TIMEOUT_CONFIG + " config is deprecated and will be removed soon. " +
                    "Please use " + ProducerConfig.MAX_BLOCK_MS_CONFIG);
            this.maxBlockTimeMs = config.getLong(ProducerConfig.METADATA_FETCH_TIMEOUT_CONFIG);
        } else {
            this.maxBlockTimeMs = config.getLong(ProducerConfig.MAX_BLOCK_MS_CONFIG);
        }

        /* check for user defined settings.
         * If the TIME_OUT config is set use that for request timeout.
         * This should be removed with release 0.9
         */
        //请求超时时间 request.timeout.ms，默认是30s
        if (userProvidedConfigs.containsKey(ProducerConfig.TIMEOUT_CONFIG)) {
            log.warn(ProducerConfig.TIMEOUT_CONFIG + " config is deprecated and will be removed soon. Please use " +
                    ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG);
            this.requestTimeoutMs = config.getInt(ProducerConfig.TIMEOUT_CONFIG);
        } else {
            this.requestTimeoutMs = config.getInt(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG);
        }

        //核心组件RecordAccumulator：缓冲机制，发送到每个分区的消息会被打包成 batch
        //一个 broker 上的多个分区对应的多个 batch 会被打包成一个 request
        //默认每个 batch 大小是batch.size，16K
        //达到 batch.size 或者超过linger.ms（默认0ms）等待时长就发送 batch
        this.accumulator = new RecordAccumulator(config.getInt(ProducerConfig.BATCH_SIZE_CONFIG),
                this.totalMemorySize,
                this.compressionType,
                config.getLong(ProducerConfig.LINGER_MS_CONFIG),
                retryBackoffMs,
                metrics,
                time);

        //获取 broker 对应的 ip 端口
        List<InetSocketAddress> addresses = ClientUtils.parseAndValidateAddresses(config.getList(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG));
        //初始化的时候去 broker 拉取元数据，后续每隔5分钟默认刷新一次元数据
        //这里仅仅是初始化了元数据相关的数据结构，并没有真正的去拉取元数据
        this.metadata.update(Cluster.bootstrap(addresses), time.milliseconds());
        ChannelBuilder channelBuilder = ClientUtils.createChannelBuilder(config.values());
        //网络通信组件
        NetworkClient client = new NetworkClient(
                //对一个 broker 的连接最大空闲时间connections.max.idle.ms默认9分钟，超过需要回收
                new Selector(config.getLong(ProducerConfig.CONNECTIONS_MAX_IDLE_MS_CONFIG), this.metrics, time, "producer", channelBuilder),
                this.metadata,
                clientId,
                //配置max.in.flight.requests.per.connection，默认是5，表示对同一个 broker 最多允许多少个 request 发送后无响应
                //如果配置大于1，消息重试后可能会造成乱序
                config.getInt(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION),
                //对 broker 连接失败的重试间隔reconnect.backoff.ms，默认50ms
                config.getLong(ProducerConfig.RECONNECT_BACKOFF_MS_CONFIG),
                //socket 默认发送请求缓冲区send.buffer.bytes，128k
                config.getInt(ProducerConfig.SEND_BUFFER_CONFIG),
                //socket 默认接收请求缓冲区send.buffer.bytes，128k
                config.getInt(ProducerConfig.RECEIVE_BUFFER_CONFIG),
                this.requestTimeoutMs, time);
        //sender 是Runnable
        this.sender = new Sender(client,
                this.metadata,
                this.accumulator,
                //判断是否需要保证消息顺序
                config.getInt(ProducerConfig.MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION) == 1,
                //发送 request请求最大大小max.request.size，默认1M
                config.getInt(ProducerConfig.MAX_REQUEST_SIZE_CONFIG),
                //acks
                //0：表示消息发送后就返回，不会等待任何响应机制，无法确定消息是否发送成功
                //1（默认）：表示消息往leader发送成功后，不需要等其他 follower 同步完就直接返回成功
                //all/-1：表示消息需要成功发送给leader 和所有 follower 才算成功
                (short) parseAcks(config.getString(ProducerConfig.ACKS_CONFIG)),
                //retries：默认是0不会重试
                config.getInt(ProducerConfig.RETRIES_CONFIG),
                this.metrics,
                new SystemTime(),
                clientId,
                //请求超时时间，默认30s
                this.requestTimeoutMs);
        String ioThreadName = "kafka-producer-network-thread" + (clientId.length() > 0 ? " | " + clientId : "");
        //将 sender 封装为 ioThread 线程
        //线程以及线程执行的逻辑切分开
        this.ioThread = new KafkaThread(ioThreadName, this.sender, true);
        //启动 sender 线程
        this.ioThread.start();

        this.errors = this.metrics.sensor("errors");

        //序列化组件
        if (keySerializer == null) {
            this.keySerializer = config.getConfiguredInstance(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,
                    Serializer.class);
            this.keySerializer.configure(config.originals(), true);
        } else {
            config.ignore(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG);
            this.keySerializer = keySerializer;
        }
        if (valueSerializer == null) {
            this.valueSerializer = config.getConfiguredInstance(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,
                    Serializer.class);
            this.valueSerializer.configure(config.originals(), false);
        } else {
            config.ignore(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG);
            this.valueSerializer = valueSerializer;
        }

        //拦截器组件
        // load interceptors and make sure they get clientId
        userProvidedConfigs.put(ProducerConfig.CLIENT_ID_CONFIG, clientId);
        List<ProducerInterceptor<K, V>> interceptorList = (List) (new ProducerConfig(userProvidedConfigs)).getConfiguredInstances(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG,
                ProducerInterceptor.class);
        this.interceptors = interceptorList.isEmpty() ? null : new ProducerInterceptors<>(interceptorList);

        config.logUnused();
        AppInfoParser.registerAppInfo(JMX_PREFIX, clientId);
        log.debug("Kafka producer started");
    } catch (Throwable t) {
        // call close methods if internal objects are already constructed
        // this is to prevent resource leak. see KAFKA-2121
        close(0, TimeUnit.MILLISECONDS, true);
        // now propagate the exception
        throw new KafkaException("Failed to construct kafka producer", t);
    }
}
```

# 消息发送对象ProducerRecord

生产者客户端发送消息时，消息会被封装为ProducerRecord对象

```java
public final class ProducerRecord<K, V> {

    private final String topic;
    private final Integer partition;
    private final K key;
    private final V value;
    private final Long timestamp;
}	
```

# 生产者发送消息doSend方法

```java
private Future<RecordMetadata> doSend(ProducerRecord<K, V> record, Callback callback) {
    TopicPartition tp = null;
    try {
        //同步阻塞等待获取topic元数据，并且最多可等待超时时间maxBlockTimeMs
        long waitedOnMetadataMs = waitOnMetadata(record.topic(), this.maxBlockTimeMs);
        //计算剩余可等待的时间
        long remainingWaitMs = Math.max(0, this.maxBlockTimeMs - waitedOnMetadataMs);
        //序列化key和value为字节数组
        byte[] serializedKey;
        try {
            serializedKey = keySerializer.serialize(record.topic(), record.key());
        } catch (ClassCastException cce) {
            throw new SerializationException("Can't convert key of class " + record.key().getClass().getName() +
                    " to class " + producerConfig.getClass(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG).getName() +
                    " specified in key.serializer");
        }
        byte[] serializedValue;
        try {
            serializedValue = valueSerializer.serialize(record.topic(), record.value());
        } catch (ClassCastException cce) {
            throw new SerializationException("Can't convert value of class " + record.value().getClass().getName() +
                    " to class " + producerConfig.getClass(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG).getName() +
                    " specified in value.serializer");
        }
        //基于获取到的topic元数据，使用Partitioner组件获取消息对应的分区
        int partition = partition(record, serializedKey, serializedValue, metadata.fetch());
        //计算序列化后的消息长度=添加固定的12字节长度+key 字节数据长度+value 字节数组长度+其他固定字段长度
        int serializedSize = Records.LOG_OVERHEAD + Record.recordSize(serializedKey, serializedValue);
        //校验缓冲区（32M）和消息(1M)的最大长度
        ensureValidRecordSize(serializedSize);
        //封装 topic 和分区数据
        tp = new TopicPartition(record.topic(), partition);
        long timestamp = record.timestamp() == null ? time.milliseconds() : record.timestamp();
        log.trace("Sending record {} with callback {} to topic {} partition {}", record, callback, record.topic(), partition);
        // producer callback will make sure to call both 'callback' and interceptor callback
        //设置好自定义的callback、interceptor拦截器的回调函数
        Callback interceptCallback = this.interceptors == null ? callback : new InterceptorCallback<>(callback, this.interceptors, tp);
        //RecordAccumulator组件将消息添加到内存缓冲里去
        RecordAccumulator.RecordAppendResult result = accumulator.append(tp, timestamp, serializedKey, serializedValue, interceptCallback, remainingWaitMs);
        //如果某个分区对应的 batch 满了，或者是新创建了一个 batch，此时会唤醒 Sender 线程，让它进行工作，负责发送 batch
        if (result.batchIsFull || result.newBatchCreated) {
            log.trace("Waking up the sender since topic {} partition {} is either full or getting a new batch", record.topic(), partition);
            this.sender.wakeup();
        }
        return result.future;
        // handling exceptions and record the errors;
        // for API exceptions return them in the future,
        // for other exceptions throw directly
        //异常处理机制
    } catch (ApiException e) {
        log.debug("Exception occurred during message send:", e);
        if (callback != null)
            callback.onCompletion(null, e);
        this.errors.record();
        if (this.interceptors != null)
            this.interceptors.onSendError(record, tp, e);
        return new FutureFailure(e);
    } catch (InterruptedException e) {
        this.errors.record();
        if (this.interceptors != null)
            this.interceptors.onSendError(record, tp, e);
        throw new InterruptException(e);
    } catch (BufferExhaustedException e) {
        this.errors.record();
        this.metrics.sensor("buffer-exhausted-records").record();
        if (this.interceptors != null)
            this.interceptors.onSendError(record, tp, e);
        throw e;
    } catch (KafkaException e) {
        this.errors.record();
        if (this.interceptors != null)
            this.interceptors.onSendError(record, tp, e);
        throw e;
    } catch (Exception e) {
        // we notify interceptor about all exceptions, since onSend is called before anything else in this method
        if (this.interceptors != null)
            this.interceptors.onSendError(record, tp, e);
        throw e;
    }
}
```

## Partitioner分区组件策略

消息发送给指定topic，在broker可能会有多个partition，需要有一定的策略发送给具体的一个partition。如果消息有指定partitionId，则直接发送到指定partition；否则如果有传入消息key，则通过hash后固定发送到同一个partition；否则通过计数器对总分区数取模

```java
private int partition(ProducerRecord<K, V> record, byte[] serializedKey , byte[] serializedValue, Cluster cluster) {
    Integer partition = record.partition();
    //如果消息有指定分区，则直接返回即可
    if (partition != null) {
        List<PartitionInfo> partitions = cluster.partitionsForTopic(record.topic());
        int lastPartition = partitions.size() - 1;
        // they have given us a partition, use it
        if (partition < 0 || partition > lastPartition) {
            throw new IllegalArgumentException(String.format("Invalid partition given with record: %d is not in the range [0...%d].", partition, lastPartition));
        }
        return partition;
    }
    //否则通过底层策略选出具体的分区
    return this.partitioner.partition(record.topic(), record.key(), serializedKey, record.value(), serializedValue,
        cluster);
}
```

```java
public int partition(String topic, Object key, byte[] keyBytes, Object value, byte[] valueBytes, Cluster cluster) {
    List<PartitionInfo> partitions = cluster.partitionsForTopic(topic);
    int numPartitions = partitions.size();
    //没有指定 key，则通过计数取模轮询分区
    if (keyBytes == null) {
        int nextValue = counter.getAndIncrement();
        //对可用分区数取模
        List<PartitionInfo> availablePartitions = cluster.availablePartitionsForTopic(topic);
        if (availablePartitions.size() > 0) {
            int part = DefaultPartitioner.toPositive(nextValue) % availablePartitions.size();
            return availablePartitions.get(part).partition();
        } else {
            // no partitions are available, give a non-available partition
            return DefaultPartitioner.toPositive(nextValue) % numPartitions;
        }
    } else {
        //有指定 key，则计算后取模获取指定分区
        // hash the keyBytes to choose a partition
        return DefaultPartitioner.toPositive(Utils.murmur2(keyBytes)) % numPartitions;
    }
}
```

## RecordAccumulator消息缓冲器初始化

Kafka为了提升消息吞吐量，会将消息缓存到内存，进行批量发送，提升性能。RecordAccumulator其作用相当于一个缓冲队列,会根据主题和分区(TopicPartition对象)对消息进行分组,每一个TopicPartition对象会对应一个双端队列Deque<ProducerBatch>,ProducerBatch表示一批消息,在KafkaProducer发送消息时,总是从队列队尾 (Tail)取出ProducerBatch(如果队列不为空),而Sender是从队列头(Head)取ProducerBatch进行处

```java
public final class RecordAccumulator {

    private static final Logger log = LoggerFactory.getLogger(RecordAccumulator.class);

    private volatile boolean closed;
    private final AtomicInteger flushesInProgress;
    private final AtomicInteger appendsInProgress;
    private final int batchSize;
    private final CompressionType compression;
    private final long lingerMs;
    private final long retryBackoffMs;
    private final BufferPool free;
    private final Time time;
    //CopyOnWriteMap 数据结构实现，每个分区都对应一个队列，队列中存放 batch 数据
    private final ConcurrentMap<TopicPartition, Deque<RecordBatch>> batches;
    private final IncompleteRecordBatches incomplete;
    // The following variables are only accessed by the sender thread, so we don't need to protect them.
    private final Set<TopicPartition> muted;
    private int drainIndex;
}		

public RecordAccumulator(int batchSize,
                         long totalSize,
                         CompressionType compression,
                         long lingerMs,
                         long retryBackoffMs,
                         Metrics metrics,
                         Time time) {
    this.drainIndex = 0;
    this.closed = false;
    this.flushesInProgress = new AtomicInteger(0);
    this.appendsInProgress = new AtomicInteger(0);
    this.batchSize = batchSize;
    this.compression = compression;
    this.lingerMs = lingerMs;
    this.retryBackoffMs = retryBackoffMs;
    this.batches = new CopyOnWriteMap<>();
    String metricGrpName = "producer-metrics";
    this.free = new BufferPool(totalSize, batchSize, metrics, time, metricGrpName);
    this.incomplete = new IncompleteRecordBatches();
    this.muted = new HashSet<>();
    this.time = time;
    registerMetrics(metrics, metricGrpName);
}
```

生产者发送消息，调用的是append方法，用于将消息添加到缓冲器，然后返回追加的结果，结果会包含异步的future和标识（标识追加的batch是否已满或者是否是创建的新batch）

```java
public RecordAppendResult append(TopicPartition tp,
                                 long timestamp,
                                 byte[] key,
                                 byte[] value,
                                 Callback callback,
                                 long maxTimeToBlock) throws InterruptedException {
    // We keep track of the number of appending thread to make sure we do not miss batches in
    // abortIncompleteBatches().
    //KafkaProducer 是线程安全，这里计数统计并发发送消息的线程数
    appendsInProgress.incrementAndGet();
    try {
        // check if we have an in-progress batch
        //根据TopicPartition获取or创建消息对应的双端队列Deque<ProducerBatch>,并与其进行关联
        Deque<RecordBatch> dq = getOrCreateDeque(tp);
        //保证多线程情况下，同一 topic 相同分区的消息能够顺序写入
        //这样就保证了同一分区的消息在客户端 buffer 中是有序的
        synchronized (dq) {
            if (closed)
                throw new IllegalStateException("Cannot send after the producer is closed.");
            //尝试将消息写入队列队尾的 RecordBatch 中，如果返回 null 则写入失败（dq 队列 RecordBatch 为空或者 RecordBatch 空间不足）
            RecordAppendResult appendResult = tryAppend(timestamp, key, value, callback, dq);
            //如果写入batch成功直接返回
            if (appendResult != null)
                return appendResult;
        }

        //若上述尝试append消息失败,即返回null,此时需要向BufferPool申请空间用于创建新的ProducerBatch对象

        // we don't have an in-progress record batch try to allocate a new batch
        //取消息大小和batchSize(默认16KB)较大值作为要申请的内存空间大小
        //需要对 request.max.size 和 batch.size 进行调优，否则一个 batch 就是一条消息，每条消息都对应一次网络请求，batch 打包机制就没有意义
        int size = Math.max(this.batchSize, Records.LOG_OVERHEAD + Record.recordSize(key, value));
        log.trace("Allocating a new {} byte message buffer for topic {} partition {}", size, tp.topic(), tp.partition());
        //从BufferPool申请内存空间
        ByteBuffer buffer = free.allocate(size, maxTimeToBlock);
        //并发问题：
        //对于同一个 topic的dq队列，在队列为空或者空间不足，多个线程可能会并发申请到 ByteBuffer
        //但是进入到同步块后，第一个线程会基于ByteBuffer创建一个 batch 放入到dq队列中
        //后续线程再次进入到同步块，会将消息直接放入到dq队列队尾 batch，并且释放自己所申请的ByteBuffer内存，放回到缓冲池队列中供复用
        synchronized (dq) {
            // Need to check if producer is closed again after grabbing the dequeue lock.
            if (closed)
                throw new IllegalStateException("Cannot send after the producer is closed.");
            //double-check再次尝试将消息写入到队列的最近一个 batch 中
            RecordAppendResult appendResult = tryAppend(timestamp, key, value, callback, dq);
            if (appendResult != null) {
                // Somebody else found us a batch, return the one we waited for! Hopefully this doesn't happen often...
                // appendResult不为空，说明 dq 队列中有 batch，并且消息写入成功。此时释放当前线程所申请的 ByteBuffer，放回到缓冲池队列中供复用
                free.deallocate(buffer);
                return appendResult;
            }
            //将 buffer 封装为MemoryRecords
            MemoryRecords records = MemoryRecords.emptyRecords(buffer, compression, this.batchSize);
            //将MemoryRecords封装为RecordBatch
            RecordBatch batch = new RecordBatch(tp, records, time.milliseconds());
            //将消息写入到RecordBatch
            FutureRecordMetadata future = Utils.notNull(batch.tryAppend(timestamp, key, value, callback, time.milliseconds()));

            //将当前ByteBuffer（batch）添加到 dq 队尾
            dq.addLast(batch);
            incomplete.add(batch);
            return new RecordAppendResult(future, dq.size() > 1 || batch.records.isFull(), true);
        }
    } finally {
        appendsInProgress.decrementAndGet();
    }
}
```

## 消息存储的数据结构CopyOnWriteMap

消息所属的topic+partition会分配一个队列，用于存储RecordBatch，每个RecordBatch包含多个消息记录

```java
private Deque<RecordBatch> getOrCreateDeque(TopicPartition tp) {
    //batches 底层的 map 是通过 volatile 修饰的，多个线程并发的读不需要加锁
    Deque<RecordBatch> d = this.batches.get(tp);
    if (d != null)
        return d;
    d = new ArrayDeque<>();
    //修改 batches 方法会通过synchronized加锁
    //对当前维护的 map 生成新的副本，针对副本修改完后再通过 volatile 写的方式赋值给原 map，不会对读操作有影响
    //一个分区修改一次，符合读多写少的场景
    Deque<RecordBatch> previous = this.batches.putIfAbsent(tp, d);
    if (previous == null)
        return d;
    else
        return previous;
}
```

自定义的CopyOnWriteMap数据结构，是ConcurrentMap的实现，所有的读无需加锁，但是会对写进行synchronized同步，并且写操作后会将操作后的map重新赋值给所维护的Map，实现类似于CopyOnWriteArrayList

RecordBatch所在的队列是`private final ConcurrentMap<TopicPartition, Deque<RecordBatch>> batches;`来维护

```java
public class CopyOnWriteMap<K, V> implements ConcurrentMap<K, V> {

    private volatile Map<K, V> map;

    public CopyOnWriteMap() {
        this.map = Collections.emptyMap();
    }

    public CopyOnWriteMap(Map<K, V> map) {
        this.map = Collections.unmodifiableMap(map);
    }

    @Override
    public synchronized V put(K k, V v) {
        Map<K, V> copy = new HashMap<K, V>(this.map);
        V prev = copy.put(k, v);
        this.map = Collections.unmodifiableMap(copy);
        return prev;
    }

    @Override
    public V get(Object k) {
        return map.get(k);
    }
    ...
}
```

## 消息追加至RecordBatch

```java
private RecordAppendResult tryAppend(long timestamp, byte[] key, byte[] value, Callback callback, Deque<RecordBatch> deque) {
    //获取队尾一个 batch
    RecordBatch last = deque.peekLast();
    if (last != null) {
        //将消息写入到 batch 中
        FutureRecordMetadata future = last.tryAppend(timestamp, key, value, callback, time.milliseconds());
        if (future == null)
            //将底层的 io 流关闭，更新可写标识位，只能进行读
            last.records.close();
        else
            return new RecordAppendResult(future, deque.size() > 1 || last.records.isFull(), false);
    }
    //队列中没有 batch，或者 batch 空间不足， 则返回 null
    return null;
}
```

追加消息到record集合，并且返回基于该集合的相对offset

```java
public FutureRecordMetadata tryAppend(long timestamp, byte[] key, byte[] value, Callback callback, long now) {
    //校验batch是否有足够空间写入消息
    if (!this.records.hasRoomFor(key, value)) {
        return null;
    } else {
        long checksum = this.records.append(offsetCounter++, timestamp, key, value);
        //记录最大的消息长度
        this.maxRecordSize = Math.max(this.maxRecordSize, Record.recordSize(key, value));
        //最近写入消息数据时间
        this.lastAppendTime = now;
        //封装返回结果
        FutureRecordMetadata future = new FutureRecordMetadata(this.produceFuture, this.recordCount,
                                                               timestamp, checksum,
                                                               key == null ? -1 : key.length,
                                                               value == null ? -1 : value.length);
        if (callback != null)
            thunks.add(new Thunk(callback, future));
        this.recordCount++;
        return future;
    }
}
```

追加消息和offset至底层Buffer缓冲区

```java
public long append(long offset, long timestamp, byte[] key, byte[] value) {
    if (!writable)
        throw new IllegalStateException("Memory records is not writable");

    int size = Record.recordSize(key, value);
    //先写offset
    compressor.putLong(offset);
    //再写消息大小
    compressor.putInt(size);
    //实际写入消息数据 crc|magic|attributes|timestamp|key size|key|value size|value
    long crc = compressor.putRecord(timestamp, key, value);
    //更新 batch 中的消息数和总大小
    compressor.recordWritten(size + Records.LOG_OVERHEAD);
    return crc;
}
```

一条消息写入磁盘的数据格式如下：

```java
public static void write(Compressor compressor, long crc, byte attributes, long timestamp, byte[] key, byte[] value, int valueOffset, int valueSize) {
    // write crc
    compressor.putInt((int) (crc & 0xffffffffL));
    // write magic value
    compressor.putByte(CURRENT_MAGIC_VALUE);
    // write attributes
    compressor.putByte(attributes);
    // write timestamp
    compressor.putLong(timestamp);
    // write the key
    if (key == null) {
        compressor.putInt(-1);
    } else {
        compressor.putInt(key.length);
        compressor.put(key, 0, key.length);
    }
    // write the value
    if (value == null) {
        compressor.putInt(-1);
    } else {
        int size = valueSize >= 0 ? valueSize : (value.length - valueOffset);
        compressor.putInt(size);
        compressor.put(value, valueOffset, size);
    }
}
```

# 内存缓冲池BufferPool

kafka生产者send一条记录(record)后并没有直接发送到kafka服务端，而是先将它保存到内存(RecordAccumulator)中，用于压缩之后批量发送，这里内存的创建和释放是比较消耗资源的，为了实现内存的高效利用，基本上每个成熟的框架或者工具都有一套内存管理机制，kafka的生产者使用BufferPool来实现内存(ByteBuffer)的复用

```java
public final class BufferPool {

    //总的内存缓冲区大小。默认是32M
    private final long totalMemory;
    //batch 大小，默认16Kb
    private final int poolableSize;
    private final ReentrantLock lock;
    //队列缓存了一批内存空间，用来复用
    private final Deque<ByteBuffer> free;
    private final Deque<Condition> waiters;
    //剩下可用的内存空间大小
    private long availableMemory;
    private final Metrics metrics;
    private final Time time;
    private final Sensor waitTime;
}

public BufferPool(long memory, int poolableSize, Metrics metrics, Time time, String metricGrpName) {
    this.poolableSize = poolableSize;
    this.lock = new ReentrantLock();
    this.free = new ArrayDeque<ByteBuffer>();
    this.waiters = new ArrayDeque<Condition>();
    this.totalMemory = memory;
    this.availableMemory = memory;
    this.metrics = metrics;
    this.time = time;
    this.waitTime = this.metrics.sensor("bufferpool-wait-time");
    MetricName metricName = metrics.metricName("bufferpool-wait-ratio",
                                               metricGrpName,
                                               "The fraction of time an appender waits for space allocation.");
    this.waitTime.add(metricName, new Rate(TimeUnit.NANOSECONDS));
}
```

通过指定的大小申请buffer内存空间，如果缓冲池内存空间不足，则调用会被阻塞

总的缓冲区内存大小=availableMemory剩余可用缓存区大小+free缓冲区队列持有的内存大小+正在使用的batch内存大小

```java
public ByteBuffer allocate(int size, long maxTimeToBlockMs) throws InterruptedException {
    //需要分配的内存大小大于总的缓冲区大小则抛异常
    if (size > this.totalMemory)
        throw new IllegalArgumentException("Attempt to allocate " + size
                                           + " bytes, but there is a hard limit of "
                                           + this.totalMemory
                                           + " on memory allocations.");

    //申请内存空间需要加锁
    this.lock.lock();
    try {
        // check if we have a free buffer of the right size pooled
        //如果需要申请的内存大小是batchSize，并且BufferPool中的free空闲链表有可用使用的内存块，直接复用
        if (size == poolableSize && !this.free.isEmpty())
            return this.free.pollFirst();

        //否则可能是需要申请的size不符合batchSize，或者free链表为空没有足够的内存块

        // now check if the request is immediately satisfiable with the
        // memory on hand or if we need to block
        //计算BufferPool中free空闲内存大小
        int freeListSize = this.free.size() * this.poolableSize;
        //缓冲区剩余可使用内存大小+BufferPool中free空闲内存大小=可分配总的缓冲区>需要分配的 size 内存大小
        if (this.availableMemory + freeListSize >= size) {
            // we have enough unallocated or pooled memory to immediately
            // satisfy the request
            //确保内存空间足够分配 size 内存大小
            //如果availableMemory大小不足以分配给指定size大小，则从free中释放空间给到availableMemory
            //直到availableMemory足够分配size大小为止
            freeUp(size);
            //availableMemory可用空间进行分配
            this.availableMemory -= size;
            lock.unlock();
            //通过 nio 分配堆内存
            return ByteBuffer.allocate(size);
        } else {
            //总的内存缓存空间不足，需要阻塞等待 batch 成功发送后释放内存空间
            // we are out of memory and will have to block
            int accumulated = 0;
            ByteBuffer buffer = null;
            Condition moreMemory = this.lock.newCondition();
            //最大阻塞等待时间
            long remainingTimeToBlockNs = TimeUnit.MILLISECONDS.toNanos(maxTimeToBlockMs);
            //放入到队列中
            this.waiters.addLast(moreMemory);
            // loop over and over until we have a buffer or have reserved
            // enough memory to allocate one
            //循环等待直到有足够的内存释放出来
            while (accumulated < size) {
                long startWaitNs = time.nanoseconds();
                long timeNs;
                boolean waitingTimeElapsed;
                try {
                    //阻塞等待有 batch 被发送成功，内存清空后会通知此处唤醒
                    waitingTimeElapsed = !moreMemory.await(remainingTimeToBlockNs, TimeUnit.NANOSECONDS);
                } catch (InterruptedException e) {
                    this.waiters.remove(moreMemory);
                    throw e;
                } finally {
                    long endWaitNs = time.nanoseconds();
                    timeNs = Math.max(0L, endWaitNs - startWaitNs);
                    this.waitTime.record(timeNs, time.milliseconds());
                }

                if (waitingTimeElapsed) {
                    this.waiters.remove(moreMemory);
                    throw new TimeoutException("Failed to allocate memory within the configured max blocking time " + maxTimeToBlockMs + " ms.");
                }

                remainingTimeToBlockNs -= timeNs;
                // check if we can satisfy this request from the free list,
                // otherwise allocate memory

                //如果 batch 释放后，对应BufferPool中free内存大小有可复用的内存空间，则直接使用
                //否则进行内存直接分配
                if (accumulated == 0 && size == this.poolableSize && !this.free.isEmpty()) {
                    // just grab a buffer from the free list
                    buffer = this.free.pollFirst();
                    accumulated = size;
                } else {
                    //否则直接从availableMemory中分配
                    // we'll need to allocate memory, but we may only get
                    // part of what we need on this iteration
                    freeUp(size - accumulated);
                    int got = (int) Math.min(size - accumulated, this.availableMemory);
                    this.availableMemory -= got;
                    accumulated += got;
                }
            }

            // remove the condition for this thread to let the next thread
            // in line start getting memory
            Condition removed = this.waiters.removeFirst();
            if (removed != moreMemory)
                throw new IllegalStateException("Wrong condition: this shouldn't happen.");

            //如果有多余的内存空间，则继续唤醒分配
            // signal any additional waiters if there is more memory left
            // over for them
            if (this.availableMemory > 0 || !this.free.isEmpty()) {
                if (!this.waiters.isEmpty())
                    this.waiters.peekFirst().signal();
            }

            // unlock and return the buffer
            //如果从free中复用的内存直接使用即可，否则需要重新分配
            lock.unlock();
            if (buffer == null)
                return ByteBuffer.allocate(size);
            else
                return buffer;
        }
    } finally {
        if (lock.isHeldByCurrentThread())
            lock.unlock();
    }
}
```

缓冲区释放，每个TopicPartition对应的RecordBatch队列，队列只需要有一个batch用来写入数据，如果写满后续再申请一个batch即可。在极端并发情况下，多个线程可能会申请到多块内存缓冲buffer，但是在一个线程将申请到的buffer追加到RecordBatch队列后，后续的其他线程可以直接使用队列中的该buffer，所以这些线程需要释放自己所申请的buffer

```java
public void deallocate(ByteBuffer buffer, int size) {
    lock.lock();
    try {
        //如果满足缓冲池大小限制
        if (size == this.poolableSize && size == buffer.capacity()) {
            //清空内存数据
            buffer.clear();
            //返回到缓冲池供下一个batch使用
            this.free.add(buffer);
        } else {
            //否则直接返回到可用缓冲区大小
            this.availableMemory += size;
        }
        //如果之前内存已经被耗尽了，此时有线程使用了Condition阻塞在这里等待获取内存资源，
        //一旦有内存资源还回去了，此时就会使用Condition的await方法，唤醒之前阻塞等待的线程，告诉他们说，可以来尝试获取锁，然后申请内存资源了
        Condition moreMem = this.waiters.peekFirst();
        if (moreMem != null)
            moreMem.signal();
    } finally {
        lock.unlock();
    }
}
```

内存分配图

![img](2.源码分析-生产者发送消息流程解析.assets/c0a6b886b96cb404eeaf9a86e0a036b0.png)

红色和绿色的总和代表BufferPool的总量，用totalMemory表示(由buffer.memory配置)；绿色代表可使用的空间，它又包括两个部分：上半部分代表未申请未使用的部分，用availableMemory表示；下半部分代表已经申请但没有使用的部分，用一个ByteBuffer队列(Deque<ByteBuffer>)表示，我们称这个队列为free，队列中的ByteBuffer的大小用poolableSize表示(由batch.size配置)

![86c8a424fedace8ca316daba62bc2671.png](2.源码分析-生产者发送消息流程解析.assets/86c8a424fedace8ca316daba62bc2671.png)

# 流程图

![img](2.源码分析-生产者发送消息流程解析.assets/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0RlbGljaW91c19MaWZl,size_16,color_FFFFFF,t_70.png)

# 借鉴点

1.客户端初始化时，并没有去拉取元数据，而是懒加载在发送消息给 topic 时再去拉取 topic 对应元数据

2.可扩展：通过拦截器的模式预留一些扩展点，在消息发送之前或者发送之后，进行自定义的扩展

3.通用框架一定会有序列化过程，key 和 value 是各种各样类型，必须要保证都转换成通用的 byte[]字节数组的格式，再进行跟 broker 进行通信

4.基于独立封装的组件进行分区的选择和路由，可以用默认的，也可以用自定义分区器，预留扩展点

5.对核心请求数据的大小进行严格检查

6.异步发送请求，先进入内存缓冲，同时设置 callback 回调函数，发送完成后回调通知结果。同时基于异步的后台线程来发送消息

7.异常处理的标准是，底层模块一般来说都应该要把自己的网络异常、IO 异常，往上抛出来，在最核心的上层流程控制的逻辑中来捕获所有的异常，这样可以在核心流程的运行过程中，根据异常来进行对应的处理



可以看到BufferPool只针对特定大小(poolableSize)的ByteBuffer进行管理，对于其它大小的并不会缓存进来。因此如果超大消息比较多(大于poolableSize)，就不会很好的利用内存池，频繁的申请回收内存效率会降低，并可能带来Full GC或者Out Of Memory Error，这个时候就要调整好batch.size的配置了

